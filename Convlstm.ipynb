{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMjpGs1fi+LHhODeyIZbqn8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jYijAuRm5eBg","executionInfo":{"status":"ok","timestamp":1689762745504,"user_tz":-330,"elapsed":800,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"outputs":[],"source":["# Imports\n","\n","import os\n","import cv2\n","import json\n","import glob\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["# Mounting gdrive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DlHAqkWP_sXL","executionInfo":{"status":"ok","timestamp":1689762763031,"user_tz":-330,"elapsed":17543,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}},"outputId":"94e7c0e2-2b41-4163-b738-7e6cc2e53a8a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Get list of classes\n","\n","CLASSES = []\n","for i in os.scandir(\"/content/drive/MyDrive/v1.0\"):\n","  CLASSES.append(i.path.split(\"/\")[5].split(\"_\")[2])\n","print(CLASSES)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjBHozbuAGNv","executionInfo":{"status":"ok","timestamp":1689762766463,"user_tz":-330,"elapsed":835,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}},"outputId":"55f04b65-3aa2-4222-cf14-37997e5d9ac0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['birddog', 'curl', 'fly', 'legraise', 'pushup', 'superman', 'bicyclecrunch', 'squat', 'armraise', 'overheadpress']\n"]}]},{"cell_type":"code","source":["# Create Dataset folder\n","os.mkdir(\"/content/Dataset\")\n","\n","# Create folder for each class\n","for i in CLASSES:\n","  path = \"/content/Dataset/\"+i\n","  os.mkdir(path)"],"metadata":{"id":"vZYkwTT_DFlL","executionInfo":{"status":"ok","timestamp":1689762767757,"user_tz":-330,"elapsed":2,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Unzip the video files in respective class folders\n","\n","import shutil\n","\n","for i in os.scandir(\"/content/drive/MyDrive/v1.0\"):\n","  for exercise in CLASSES:\n","    des_path = path = \"/content/Dataset/\"+exercise\n","    shutil.unpack_archive(i.path, des_path)\n"],"metadata":{"id":"z60w_diJDeP4","executionInfo":{"status":"ok","timestamp":1689763416622,"user_tz":-330,"elapsed":645182,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["IMAGE_HEIGHT , IMAGE_WIDTH = 75, 75\n","\n","SEQUENCE_LENGTH = 20\n","\n","DATASET_DIR = \"/content/Dataset\""],"metadata":{"id":"b0KHUy9ZjNy6","executionInfo":{"status":"ok","timestamp":1689764875621,"user_tz":-330,"elapsed":386,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Extract,resize and normalize\n","\n","def frames_extraction(video_path):\n","    '''\n","    This function will extract the required frames from a video after resizing and normalizing them.\n","    Args:\n","        video_path: The path of the video in the disk, whose frames are to be extracted.\n","    Returns:\n","        frames_list: A list containing the resized and normalized frames of the video.\n","    '''\n","\n","    # Declare a list to store video frames.\n","    frames_list = []\n","\n","    # Read the Video File using the VideoCapture object.\n","    video_reader = cv2.VideoCapture(video_path)\n","\n","    # Get the total number of frames in the video.\n","    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Calculate the the interval after which frames will be added to the list.\n","    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n","\n","    # Iterate through the Video Frames.\n","    for frame_counter in range(SEQUENCE_LENGTH):\n","\n","        # Set the current frame position of the video.\n","        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n","\n","        # Reading the frame from the video.\n","        success, frame = video_reader.read()\n","\n","        # Check if Video frame is not successfully read then break the loop\n","        if not success:\n","            break\n","        # Crop center\n","        y, x = frame.shape[0:2]\n","        min_dim = min(y, x)\n","        start_x = (x // 2) - (min_dim // 2)\n","        start_y = (y // 2) - (min_dim // 2)\n","        cropped_frame =  frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n","\n","        # Resize the Frame to fixed height and width.\n","        resized_frame = cv2.resize(cropped_frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n","\n","        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n","        normalized_frame = resized_frame / 255\n","\n","        # Append the normalized frame into the frames list\n","        frames_list.append(normalized_frame)\n","\n","    # Release the VideoCapture object.\n","    video_reader.release()\n","\n","    # Return the frames list.\n","    return frames_list"],"metadata":{"id":"Mkx_bPp6QyRf","executionInfo":{"status":"ok","timestamp":1689764878630,"user_tz":-330,"elapsed":504,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def create_dataset():\n","\n","    # Declared Empty Lists to store the features, labels and video file path values.\n","    features = []\n","    labels = []\n","    video_files_paths = []\n","\n","    # Iterating through all the classes mentioned in the classes list\n","    for class_index, class_name in enumerate(CLASSES):\n","\n","            folder = \"/content/Dataset/\"+ class_name +\"/data\"\n","            video_paths = (sorted(glob.glob(os.path.join(folder, \"*.mp4\"))))\n","            # video_files_paths.extend(video_paths)\n","\n","            for video_file_path in video_paths:\n","\n","              # Extract the frames of the video file.\n","              frames = frames_extraction(video_file_path)\n","\n","              # So ignore the vides having frames less than the SEQUENCE_LENGTH.\n","              if len(frames) == SEQUENCE_LENGTH:\n","\n","                  # Append the data to their repective lists.\n","                  features.append(frames)\n","                  labels.append(class_index)\n","                  video_files_paths.append(video_file_path)\n","\n","    # Converting the list to numpy arrays\n","    features = np.asarray(features)\n","    labels = np.array(labels)\n","\n","    # Return the frames, class index, and video file path.\n","    return features, labels, video_files_paths"],"metadata":{"id":"LjzxmU7Xf49G","executionInfo":{"status":"ok","timestamp":1689764882660,"user_tz":-330,"elapsed":2,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["features, labels, video_files_paths = create_dataset()"],"metadata":{"id":"OQvzoo3GlDPQ","executionInfo":{"status":"ok","timestamp":1689764959891,"user_tz":-330,"elapsed":72030,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["print(features.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3GCEnYOwAqZ","executionInfo":{"status":"ok","timestamp":1689765006279,"user_tz":-330,"elapsed":354,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}},"outputId":"2f0633d6-33ba-4a6a-8acb-46f33132bf95"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["(1000, 20, 75, 75, 3)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model"],"metadata":{"id":"3GOcv907ycVY","executionInfo":{"status":"ok","timestamp":1689765007715,"user_tz":-330,"elapsed":2,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["one_hot_encoded_labels = to_categorical(labels)"],"metadata":{"id":"exAGMtZMu428","executionInfo":{"status":"ok","timestamp":1689765009157,"user_tz":-330,"elapsed":1,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n","                                                                            test_size = 0.25, shuffle = True)\n","\n",""],"metadata":{"id":"Fq5CIG0LiVFv","executionInfo":{"status":"ok","timestamp":1689765012362,"user_tz":-330,"elapsed":1016,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["features_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDbr1qyFxjAm","executionInfo":{"status":"ok","timestamp":1689765013758,"user_tz":-330,"elapsed":4,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}},"outputId":"8b9cb29c-2ae2-46ab-c7e9-b94f61f5c5ab"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(750, 20, 75, 75, 3)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["from tensorflow import keras\n","\n","def build_feature_extractor():\n","    feature_extractor = keras.applications.InceptionV3(\n","        weights=\"imagenet\",\n","        include_top=False,\n","        pooling=\"avg\",\n","        input_shape=(75, 75, 3),\n","    )\n","    preprocess_input = keras.applications.inception_v3.preprocess_input\n","\n","    inputs = keras.Input((75, 75, 3))\n","    preprocessed = preprocess_input(inputs)\n","\n","    outputs = feature_extractor(preprocessed)\n","    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n","\n","\n","feature_extractor = build_feature_extractor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkQKQBWCxq50","executionInfo":{"status":"ok","timestamp":1689765026115,"user_tz":-330,"elapsed":8225,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}},"outputId":"16a852e6-2bea-446d-e5a2-5ff336169e82"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["label_processor = keras.layers.StringLookup(\n","    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",")\n","\n","# Utility for our sequence model.\n","def get_sequence_model():\n","    class_vocab = label_processor.get_vocabulary()\n","\n","    frame_features_input = keras.Input((20, 2048))\n","    mask_input = keras.Input((20,), dtype=\"bool\")\n","\n","    # Refer to the following tutorial to understand the significance of using `mask`:\n","    # https://keras.io/api/layers/recurrent_layers/gru/\n","    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n","    x = keras.layers.GRU(8)(x)\n","    x = keras.layers.Dropout(0.4)(x)\n","    x = keras.layers.Dense(8, activation=\"relu\")(x)\n","    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n","\n","    rnn_model = keras.Model([frame_features_input, mask_input], output)\n","\n","    rnn_model.compile(\n","        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n","    )\n","    return rnn_model\n","\n","EPOCHS = 30\n","# Utility for running experiments.\n","def run_experiment():\n","    filepath = \"./tmp/video_classifier\"\n","    checkpoint = keras.callbacks.ModelCheckpoint(\n","        filepath, save_weights_only=True, save_best_only=True, verbose=1\n","    )\n","\n","    seq_model = get_sequence_model()\n","    history = seq_model.fit(\n","        [train_data[0], train_data[1]],\n","        train_labels,\n","        validation_split=0.3,\n","        epochs=EPOCHS,\n","        callbacks=[checkpoint],\n","    )\n","\n","    seq_model.load_weights(filepath)\n","    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","    return history, seq_model\n","\n","\n","_, sequence_model = run_experiment()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"Wl66BN6z2Gu-","executionInfo":{"status":"error","timestamp":1689765909286,"user_tz":-330,"elapsed":375,"user":{"displayName":"MADHUMITHA 20MIA1045","userId":"17179411901208283514"}},"outputId":"19b04136-1ab5-4efc-8c32-5c9d4f616a7b"},"execution_count":37,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-0e5a966f1dae>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-37-0e5a966f1dae>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mseq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sequence_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     history = seq_model.fit(\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-0e5a966f1dae>\u001b[0m in \u001b[0;36mget_sequence_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Utility for our sequence model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_sequence_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclass_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mframe_features_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'label_processor' is not defined"]}]}]}